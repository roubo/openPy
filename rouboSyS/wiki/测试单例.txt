Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2013-07-08T21:33:56+08:00

====== 测试单例 ======
Created 星期一 08 七月 2013
file:///home/roubo
该页面主要收集系统开发过程中的测试单例，这些内容一般是系统的原型机。

一、语音识别子系统测试单例

该单例主要使用pocketphinx作为语音识别功能的核心，实现对计算机内一些现有“执行控制库”（定义见子系统框图）指令的反应。
单例安装系统控制流的规划，属于核心控制进程中的被动状态下的本地指令接收和执行。涉及系统感知等多个子系统，但是该单例不具体体现出来。

1、功能描述
该单例实现在系统开机以后，可通过发出“工作模式”和“放松模式”两种语音指令，来打开相应的一系列应用程序，系统在开机之后，只接收一次指令控制，之后便停止单例运行。

2、单例结构
如下图所示，为测试单例基本结构：

{{../语音识别测试单例.png}}

3、实现的步骤：
（1）为系统安装pocketsphinx，简单训练，或直接使用自带英语（或者中文）语音模型和语言模型；
（2）使用pocketsphinx的C 和python接口，实现一个针对其的感知识别接口层，预留C或Python接口;
（3）主协调控制进程使用Python语言实现对感知识别接口层的访问和功能命令集的执行;
（4）辅助控制进程使用shell脚本打包功能命令集，以及使用语音识别核心的tool进行训练等辅助功能;
（5）上述功能基本实现之后，继续补充感知识别接口层和功能命令集，完成单例使命。

4、具体代码的语言组织结构
怎么样的代码布局？一个稳定的优秀的系统应该是一个适当简单的系统。
下面做三种最终交互接口的假设：
（1）假设1,使用Python作为最终交互接口语言
#1 需要该Python程序作为一个守护进程运行；
#2 需要使用Python整合所有控制逻辑，协调系统的运行，解析其组件之间的ＩＯ；
#3 多线程，多进程的支持；
#4 线程和进程之间的通讯支持；
## 不仅可以直接调用应用程序，还可以调用应用程序接口。

（2）假设2,使用SHELL作为最终交互接口语言
#1 粘合各现成组件；
#2 逻辑处理；
#3 类多进程运行支持；
#4 解析各组件之间的通讯和IO;
##可以方便地进行各组件工具集之间的管理。

（3）假设3,使用Ｃ作为最终交互接口语言
##可行，但是为了系统的分布式和多样性，弃用。

（4）抉择和最终效果
rouboSyS智能系统不应该是一个单一的系统，但也不应该偏离“简单”的概念。综合上面的假设，我选择假设1。
具体的原因也许是如下图的简单结构，至少可以结构简单但又有良好的扩展性：
{{../代码语言布局.png}}

5、主协调控制进程的进程特性
该进程应该是一个核心进程，至少是这样的：
（1）所有子进程和相关任务都被其控制；
（2）自身而言是一个多任务并行的进程。
基于是Python的进程，假设的core.py应该有如下简单特性：
（1）core.py在开机之后的适当时刻开始运行；
（2）生成多个子进程：
1）Drecogn监听识别进程（自主运行，shell脚本封装）；
2）通讯和同步进程；
3）待命的任务脚本进程。

6、测试单例代码树
.
├── Ears
│   └── TestLi
│       ├── AC 辅助控制
│       │   ├── EarTrain 语音训练
│       │   │   ├── data
│       │   │   │   ├── en
│       │   │   │   │   ├── testli.dic
│       │   │   │   │   └── testli.lm
│       │   │   │   └── zh
│       │   │   │       ├── arctic.arpa
│       │   │   │       ├── arctic.binlm
│       │   │   │       ├── arctic.dic
│       │   │   │       ├── arctic.DMP
│       │   │   │       ├── arctic.fileids
│       │   │   │       ├── arctic.idngram
│       │   │   │       ├── arctic.tmp.arpa
│       │   │   │       ├── arctic.tmp.idngram
│       │   │   │       ├── arctic.tmp.vocab
│       │   │   │       ├── arctic.transcription
│       │   │   │       ├── arctic.txt
│       │   │   │       └── arctic.vocab
│       │   │   └── eartrain.sh
│       │   └── README.txt
│       ├── FOS  功能命令集
│       │   ├── order_Drecogn_commumication
│       │   ├── order_Drecogn.sh
│       │   ├── order_Restmode.sh
│       │   ├── order_Workmode.sh
│       │   ├── README.txt
│       │   └── WorkmodeSets
│       │       ├── GIT.sh
│       │       ├── SSH-D
│       │       └── workready.sh
│       ├── FRL 传感识别层
│       │   ├── DL
│       │   │   ├── Drecogn
│       │   │   ├── Drecogn.c
│       │   │   ├── Drecogn.o
│       │   │   ├── Makefile
│       │   │   └── order_Drecogn_commumication
│       │   ├── README.txt
│       │   └── SL
│       │       ├── a.out
│       │       ├── Makefile
│       │       ├── Srecogn
│       │       ├── Srecogn.c
│       │       └── Srecogn.o
│       └── MC 主协调控制
│           └── MainCtl.sh


二、视频识别与检测子系统测试单例
该单例使用openCV作为视频处理的引擎。
1、功能描述
该测试单例主要完成两种算法切换：运动识别和人脸识别，并且使该两种能够协调工作。在切换过程中还需实现类近焦和远焦的切换，这里对
较高分辨率摄像头进行分辨率切换和开窗处理实现。并期望完善测试单例的代码结构。

2、单例结构
为了保持一致性，该单例采用统一的布局。
{{../视频识别与检测测试单例.png}}

3、实现步骤
（1）完成该单例的算法切换引擎的“变焦”过程；
（2）运动识别“隐式”改造；
（3）给出运动识别的感兴趣坐标；
（4）根据感兴趣坐标做“变焦”；
（5）结合两种识别的共同信息，完善输出决策；
（6）美化输出结果。
